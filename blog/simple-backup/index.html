<!doctype html><html lang=en-us data-theme><head><meta charset=utf-8><meta name=HandheldFriendly content="True"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=referrer content="no-referrer-when-downgrade"><title>How I back up my small servers - Bonnee's space</title>
<meta name=description content="A personal blog for projects and thoughts"><link rel=icon href="https://github.com/Bonnee.png?size=64"><link rel=apple-touch-icon-precomposed href="https://github.com/Bonnee.png?size=64"><link rel=stylesheet href=https://www.bonnee.me/css/style.min.930c6fce9dcdde89718c3a768aad3dd95f661c258583e3b1b8ed1d833e833486.css integrity="sha256-kwxvzp3N3olxjDp2iq092V9mHCWFg+OxuO0dgz6DNIY="><meta property="og:title" content="How I back up my small servers"><meta property="og:description" content="We all have heard about horror stories concerning SD card reliability when (mis)used as root disks on SBCs; With such a track record a good backup strategy should always be in place to prevent data loss and shorten downtime when a failure occurs. Fortunately I only had one MicroSD card casualty over the years, and the following backup method did its job right to recover from it.
I like to store backups on the local network because it is faster, easier to access and safer (I don&rsquo;t encrypt my backups)."><meta property="og:type" content="article"><meta property="og:url" content="https://www.bonnee.me/blog/simple-backup/"><meta property="article:section" content="blog"><meta property="article:published_time" content="2020-12-24T22:35:17+01:00"><meta property="article:modified_time" content="2020-12-24T22:35:17+01:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="How I back up my small servers"><meta name=twitter:description content="We all have heard about horror stories concerning SD card reliability when (mis)used as root disks on SBCs; With such a track record a good backup strategy should always be in place to prevent data loss and shorten downtime when a failure occurs. Fortunately I only had one MicroSD card casualty over the years, and the following backup method did its job right to recover from it.
I like to store backups on the local network because it is faster, easier to access and safer (I don&rsquo;t encrypt my backups)."></head><body><a class=skip-main href=#main>Skip to main content</a><div class=container><header class=common-header><h1 class=site-title><a href=/>Bonnee's space</a></h1><nav><a href=https://www.bonnee.me/about title>about</a>
<a href=https://www.bonnee.me/projects title>projects</a>
<a href=https://www.bonnee.me/blog title>blog</a>
<a href=https://gallery.bonnee.me title>gallery</a>
<a href=https://t.me/bonnys_space title>μblog</a>
<a href=https://www.bonnee.me/index.xml title>rss</a></nav></header><main id=main tabindex=-1><article class=post><header class=post-header><h1 class=post-title>How I back up my small servers</h1></header><div class=post-info><div class=post-date>2020-12-24</div><div class=post-taxonomies><ul class=post-categories><li><a href=https://www.bonnee.me/categories/>blog</a></li></ul><ul class=post-tags><li><a href=https://www.bonnee.me/tags/homelab>#homelab</a></li><li><a href=https://www.bonnee.me/tags/sbc>#sbc</a></li><li><a href=https://www.bonnee.me/tags/raspberrypi>#raspberrypi</a></li></ul></div></div><div class=content><p>We all have heard about horror stories concerning SD card reliability when (mis)used as root disks on SBCs; With such a track record a good backup strategy should always be in place to prevent data loss and shorten downtime when a failure occurs. Fortunately I only had one MicroSD card casualty over the years, and the following backup method did its job right to recover from it.</p><p>I like to store backups on the local network because it is faster, easier to access and safer (I don&rsquo;t encrypt my backups). As a backup server I rely on an ancient NAS I decommissioned a few yars ago because it was too slow for media storage (we&rsquo;re talking single-core SPARC CPU with 1G of RAM). Although pretty old, the NAS was fitted with a pair of brand-new 2TB WD Reds so data should still be relatively safe. Storage is made available on the LAN through NFS with reasonable transfer speeds.</p><p>As for software I prefer dumping full disk images because it makes recovery such a breeze. Of course this approach is feasible only on easily-removable low-capacity media, like MicroSD cards or small SSDs.
With this setup recovers I am able to recover a dead Raspberry Pi with a single shell command and about 15 minutes.
If recovery time was to be absolutely crucial, one could setup something to automatically flash a spare MicroSD every time a new backup is made, reducing recovery to just a MicroSD card swap. The obvious drawback here is the wear out of the spare MicroSD that should then be replaced with a fresh one right after the recovery procedure is done. Still, the small cost of these kind of storage solutions makes this approach viable.</p><p>System images are handled by this <a href=https://github.com/Bonnee/dotfiles/blob/master/.local/bin/backup.sh>bash script</a> I wrote back in <a href=https://github.com/Bonnee/dotfiles/commit/cb2b95213ade35f177edd80ec0f5a0a1037d847e>March 2018</a>. The script has been running weekly on every server/raspi I own (7 at the time of writing this) and it does the following stuff:</p><ol><li>mount the output storage on a temporary directory</li><li>backup the local block device to output</li><li>clean up older backups</li><li>unmount the output and cleanup the temporary directory</li></ol><p>After a few revisions of the script I added compression support via the <code>-c</code> option. This helps the system scale to bigger block devices and improves backup speeds on slower networks or on slower machines. With multi-threaded gzip compression enabled I am able to backup my server&rsquo;s 120G SSD in about 2 hours and a half with the NAS being the main bottleneck.</p><p>The current script&rsquo;s feature set is:</p><ul><li>Optional compression (<a href=https://github.com/facebook/zstd>zstd</a>, <a href=https://www.zlib.net/pigz/>pigz</a>/gzip)</li><li>Support for local and remote outputs with automounting</li><li>Auto clean of older backups (it keeps the latest three backups)</li><li>Auto removal of backup image if the backup fails</li></ul><p>I&rsquo;m very satisfied with this whole procedure since it works reliably and runs on every linux box I throw it at.
One future endeavour could be the experimentation of <a href=https://en.wikipedia.org/wiki/Delta_encoding>delta</a> patches for speeding up the backup process. Basically, instead of taking a full disk image every time, only the bits that changed are taken and are then used to update the previous backup image. I fear this technique will bring excessive complexity though.</p></div></article></main><footer class=common-footer><div class=common-footer-bottom><div class=copyright><p>© 2024 Matteo Bonora</p></div><nav><a href=mailto:bonora.matteo@gmail.com title>email</a>
<a href=https://t.me/Bonny title>telegram</a>
<a href=https://github.com/Bonnee title>github</a>
<a href=https://gitlab.com/bonnee title>gitlab</a>
<a href=https://www.linkedin.com/in/matteo-bonora-748a6b1a8/ title>linkedin</a></nav></div></footer></div></body></html>