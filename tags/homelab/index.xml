<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Homelab on Bonnee's space</title><link>https://www.bonnee.me/tags/homelab/</link><description>A personal blog for projects and thoughts (Homelab)</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 24 Dec 2020 22:35:17 +0100</lastBuildDate><atom:link href="https://www.bonnee.me/tags/homelab/index.xml" rel="self" type="application/rss+xml"/><item><title>How I back up my small servers</title><link>https://www.bonnee.me/blog/simple-backup/</link><pubDate>Thu, 24 Dec 2020 22:35:17 +0100</pubDate><guid>https://www.bonnee.me/blog/simple-backup/</guid><description>&lt;p>We all have heard about horror stories concerning SD card reliability when (mis)used as root disks on SBCs; With such a track record a good backup strategy should always be in place to prevent data loss and shorten downtime when a failure occurs. Fortunately I only had one MicroSD card casualty over the years, and the following backup method did its job right to recover from it.&lt;/p>
&lt;p>I like to store backups on the local network because it is faster, easier to access and safer (I don&amp;rsquo;t encrypt my backups). As a backup server I rely on an ancient NAS I decommissioned a few yars ago because it was too slow for media storage (we&amp;rsquo;re talking single-core SPARC CPU with 1G of RAM). Although pretty old, the NAS was fitted with a pair of brand-new 2TB WD Reds so data should still be relatively safe. Storage is made available on the LAN through NFS with reasonable transfer speeds.&lt;/p>
&lt;p>As for software I prefer dumping full disk images because it makes recovery such a breeze. Of course this approach is feasible only on easily-removable low-capacity media, like MicroSD cards or small SSDs.
With this setup recovers I am able to recover a dead Raspberry Pi with a single shell command and about 15 minutes.
If recovery time was to be absolutely crucial, one could setup something to automatically flash a spare MicroSD every time a new backup is made, reducing recovery to just a MicroSD card swap. The obvious drawback here is the wear out of the spare MicroSD that should then be replaced with a fresh one right after the recovery procedure is done. Still, the small cost of these kind of storage solutions makes this approach viable.&lt;/p>
&lt;p>System images are handled by this &lt;a href="https://github.com/Bonnee/dotfiles/blob/master/.local/bin/backup.sh">bash script&lt;/a> I wrote back in &lt;a href="https://github.com/Bonnee/dotfiles/commit/cb2b95213ade35f177edd80ec0f5a0a1037d847e">March 2018&lt;/a>. The script has been running weekly on every server/raspi I own (7 at the time of writing this) and it does the following stuff:&lt;/p>
&lt;ol>
&lt;li>mount the output storage on a temporary directory&lt;/li>
&lt;li>backup the local block device to output&lt;/li>
&lt;li>clean up older backups&lt;/li>
&lt;li>unmount the output and cleanup the temporary directory&lt;/li>
&lt;/ol>
&lt;p>After a few revisions of the script I added compression support via the &lt;code>-c&lt;/code> option. This helps the system scale to bigger block devices and improves backup speeds on slower networks or on slower machines. With multi-threaded gzip compression enabled I am able to backup my server&amp;rsquo;s 120G SSD in about 2 hours and a half with the NAS being the main bottleneck.&lt;/p>
&lt;p>The current script&amp;rsquo;s feature set is:&lt;/p>
&lt;ul>
&lt;li>Optional compression (&lt;a href="https://github.com/facebook/zstd">zstd&lt;/a>, &lt;a href="https://www.zlib.net/pigz/">pigz&lt;/a>/gzip)&lt;/li>
&lt;li>Support for local and remote outputs with automounting&lt;/li>
&lt;li>Auto clean of older backups (it keeps the latest three backups)&lt;/li>
&lt;li>Auto removal of backup image if the backup fails&lt;/li>
&lt;/ul>
&lt;p>I&amp;rsquo;m very satisfied with this whole procedure since it works reliably and runs on every linux box I throw it at.
One future endeavour could be the experimentation of &lt;a href="https://en.wikipedia.org/wiki/Delta_encoding">delta&lt;/a> patches for speeding up the backup process. Basically, instead of taking a full disk image every time, only the bits that changed are taken and are then used to update the previous backup image. I fear this technique will bring excessive complexity though.&lt;/p></description></item></channel></rss>